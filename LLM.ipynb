{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs2zGCJVlW6JYBHExtBiSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sridhartroy/AIML/blob/main/LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kdGSy1D7_h3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ebc8b1e-c442-4b3e-9013-93f3b51ec363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the file is :  20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "# Read a publicly available text file from a URL.\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\")\n",
        "file_path = (\"the-verdict.txt\")\n",
        "\n",
        "urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "print(\"Length of the file is : \", len(text))\n",
        "\n",
        "print(text[:99])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the text that was just read using reg expressions and print the length of the text before and after split\n",
        "\n",
        "import re\n",
        "\n",
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(len(preprocessed), len(text))\n",
        "\n",
        "print(preprocessed[:30])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cTSEtmq6SH0",
        "outputId": "e3eeb25f-e5ec-4c23-81f9-8f9459733a5d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690 20479\n",
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this step , we need to sort the tokenized text, remove dups, and assign an unique integer for each token.\n",
        "\n",
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "print(vocab_size, type(all_words))\n",
        "\n",
        "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
        "\n",
        "for i, item in enumerate(vocab.items()):\n",
        "    print(item)\n",
        "    if i >= 50:\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek78eVxzCwQP",
        "outputId": "67205d62-4dd6-46c6-f55b-b3e133e4b48a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130 <class 'list'>\n",
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer Class that takes in the vocab that we created. And also, we send a sample new text for tokenization and encoding to an unique integer id and then decode as well.\n",
        "class SimpleTokenizerV1:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab # vocab is a dictionary and hence str_to_int is a dictionary as well\n",
        "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "       # print(self.str_to_int)\n",
        "\n",
        "    def encode(self, text): #new input text\n",
        "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed] # creating a list\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "EKyP1B4oJJo2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the above class by instantiating it with the vocabulary we created earlier from the verdict corpus. And then encode and decode\n",
        "\n",
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "       Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(len(ids), ids)\n",
        "\n",
        "print(tokenizer.decode(ids))\n",
        "\n",
        "text1 = \"\"\"\"Mrs. said pride.\"\"\"\n",
        "ids1 = tokenizer.encode(text1)\n",
        "print(len(ids1), ids1)\n",
        "\n",
        "print(tokenizer.decode(ids1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZmZBq3nLw5j",
        "outputId": "c76344ce-2b2e-44cd-88aa-b210bc0428f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21 [1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n",
            "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n",
            "6 [1, 67, 7, 851, 793, 7]\n",
            "\" Mrs. said pride.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what about words or tokens not in the corupus like below?\n",
        "\n",
        "text2 = \"\"\"\"Mr. Sridhar said pride.\"\"\"\n",
        "ids2 = tokenizer.encode(text2)\n",
        "print(len(ids2), ids2)\n",
        "\n",
        "print(tokenizer.decode(ids2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "EgsnlXziO5iG",
        "outputId": "70fc812e-8a83-4c2a-a3e5-e75684ebe935"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Sridhar'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5c4387239cc2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\"\"Mr. Sridhar said pride.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mids2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5633fe271064>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpreprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'([,.?_!\"()\\']|--|\\s)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpreprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# creating a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-5633fe271064>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpreprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'([,.?_!\"()\\']|--|\\s)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpreprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# creating a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Sridhar'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to add some additional tokens for a. unknown b. end of source text\n",
        "\n",
        "all_tokens = sorted(set(preprocessed))\n",
        "print(len(all_tokens))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "print(len(all_tokens))\n",
        "\n",
        "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
        "print(len(vocab))\n",
        "\n",
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlVn4KnFopy_",
        "outputId": "d969cc86-2d77-4163-ccfb-9dbf50b7576f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n",
            "1132\n",
            "1132\n",
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now need to modify the tokenizer custom class to include above\n",
        "\n",
        "class SimpleTokenizerV2:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab # vocab is a dictionary and hence str_to_int is a dictionary as well\n",
        "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "       # print(self.str_to_int)\n",
        "\n",
        "    def encode(self, text): #new input text\n",
        "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        print(\"Preprocessed before token check : \" , preprocessed)\n",
        "        # now check for each token in the preprocessed against the vocab.\n",
        "        preprocessed = [item if item in self.str_to_int\n",
        "                             else \"<|unk|>\"\n",
        "                        for item in preprocessed]\n",
        "\n",
        "        ids = [self.str_to_int[s] for s in preprocessed] # creating a list\n",
        "        return ids\n",
        "\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "k5Q9kyRhXfWu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's test the new tokenizer class\n",
        "\n",
        "# with existing valid text matching tokens in the vocab\n",
        "\n",
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "       Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(len(ids), ids)\n",
        "\n",
        "text = tokenizer.decode(ids)\n",
        "print(text)\n",
        "\n",
        "# 2 unrelated texts mixed with unknown tokens\n",
        "\n",
        "text1 = \"the last he painted, Sridhar\"\n",
        "text2 = \"Hello, do you like tea?\"\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "\n",
        "print(text)\n",
        "ids = tokenizer.encode(text)\n",
        "print(len(ids), ids)\n",
        "\n",
        "text = tokenizer.decode(ids)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOq9HmF-ZhGr",
        "outputId": "896d1067-a1e8-4639-c815-e28bd055d00a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed before token check :  ['\"', 'It', \"'\", 's', 'the', 'last', 'he', 'painted', ',', 'you', 'know', ',', '\"', 'Mrs', '.', 'Gisburn', 'said', 'with', 'pardonable', 'pride', '.']\n",
            "21 [1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n",
            "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n",
            "the last he painted, Sridhar <|endoftext|> Hello, do you like tea?\n",
            "Preprocessed before token check :  ['the', 'last', 'he', 'painted', ',', 'Sridhar', '<|endoftext|>', 'Hello', ',', 'do', 'you', 'like', 'tea', '?']\n",
            "14 [988, 602, 533, 746, 5, 1131, 1130, 1131, 5, 355, 1126, 628, 975, 10]\n",
            "the last he painted, <|unk|> <|endoftext|> <|unk|>, do you like tea?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using Byte Pair Encoding algorithm for Tokenization\n",
        "!pip install tiktoken\n",
        "\n",
        "from importlib.metadata import version\n",
        "import tiktoken\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yetXDTPedlWk",
        "outputId": "8aea94ed-9665-4cb8-efd7-f4f1eb9fe89d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n",
            "tiktoken version: 0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "\n",
        "text1 = \"the last he painted, Sridhar\"\n",
        "text2 = \"Hello, do you like tea?\"\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(integers)\n",
        "\n",
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEuDwprsIWTH",
        "outputId": "62c2abe9-80c4-4fc6-937c-5abfdaa9050f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1169, 938, 339, 13055, 11, 311, 6058, 9869, 220, 50256, 18435, 11, 466, 345, 588, 8887, 30]\n",
            "the last he painted, Sridhar <|endoftext|> Hello, do you like tea?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TextIO\n",
        "# Exercise 2.1 Byte pair encoding of unknown words\n",
        "\"\"\"\n",
        "Try the BPE tokenizer from the tiktoken library on the unknown words “Akwirw ier” and print the individual token IDs. Then, call the decode function on each of the resulting integers in this list to reproduce the mapping shown in figure 2.11. Lastly, call the decode method on the token IDs to check whether it can reconstruct the original input, “Akwirw ier.”\n",
        "\"\"\"\n",
        "tokenizerR50 = tiktoken.get_encoding(\"r50k_base\")\n",
        "tokenizerP50 = tiktoken.get_encoding(\"p50k_base\")\n",
        "tokenizerCl100k = tiktoken.get_encoding(\"cl100k_base\")\n",
        "tokenizero200k = tiktoken.get_encoding(\"o200k_base\")\n",
        "\n",
        "text = \"Akwirw ier\"\n",
        "\n",
        "integers = tokenizerR50.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(\"R50 \", integers, type(integers))\n",
        "\n",
        "for i in integers:\n",
        "    print(tokenizerR50.decode([i]), \"-->\", i)\n",
        "\n",
        "\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "print(tokenizerR50.decode(integers))\n",
        "\n",
        "\n",
        "integers = tokenizerP50.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(\"P50 \", integers, type(integers))\n",
        "\n",
        "for i in integers:\n",
        "    print(tokenizerP50.decode([i]), \"-->\", i)\n",
        "\n",
        "\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "print(tokenizerP50.decode(integers))\n",
        "\n",
        "integers = tokenizerCl100k.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(\"cl100k \", integers, type(integers))\n",
        "\n",
        "for i in integers:\n",
        "    print(tokenizerCl100k.decode([i]), \"-->\", i)\n",
        "\n",
        "\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "print(tokenizerCl100k.decode(integers))\n",
        "\n",
        "\n",
        "integers = tokenizero200k.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(\"o200k \", integers, type(integers))\n",
        "\n",
        "for i in integers:\n",
        "    print(tokenizero200k.decode([i]), \"-->\", i)\n",
        "\n",
        "\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "print(tokenizero200k.decode(integers))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aL-zVEcsuOg",
        "outputId": "1e463b7a-702e-46a0-c640-19492963d8d5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R50  [33901, 86, 343, 86, 220, 959] <class 'list'>\n",
            "Ak --> 33901\n",
            "w --> 86\n",
            "ir --> 343\n",
            "w --> 86\n",
            "  --> 220\n",
            "ier --> 959\n",
            "---------------------------------\n",
            "Akwirw ier\n",
            "P50  [33901, 86, 343, 86, 220, 959] <class 'list'>\n",
            "Ak --> 33901\n",
            "w --> 86\n",
            "ir --> 343\n",
            "w --> 86\n",
            "  --> 220\n",
            "ier --> 959\n",
            "---------------------------------\n",
            "Akwirw ier\n",
            "cl100k  [32, 29700, 404, 86, 602, 261] <class 'list'>\n",
            "A --> 32\n",
            "kw --> 29700\n",
            "ir --> 404\n",
            "w --> 86\n",
            " i --> 602\n",
            "er --> 261\n",
            "---------------------------------\n",
            "Akwirw ier\n",
            "o200k  [32, 9500, 380, 86, 131455] <class 'list'>\n",
            "A --> 32\n",
            "kw --> 9500\n",
            "ir --> 380\n",
            "w --> 86\n",
            " ier --> 131455\n",
            "---------------------------------\n",
            "Akwirw ier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "# print(raw_text)\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text), type(enc_text))\n",
        "\n",
        "# do a sampling for 50 tokens\n",
        "\n",
        "enc_sample = enc_text[50:]\n",
        "#print(enc_sample)\n",
        "#print(tokenizer.decode(enc_sample))\n",
        "\n",
        "context_size = 10\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size+1]\n",
        "print(f\"x: {x}\")\n",
        "print(f\"y:      {y}\")\n",
        "\n",
        "for i in range(1, context_size+1):\n",
        "    context = enc_sample[:i]\n",
        "    desired = enc_sample[i]\n",
        "    print(context, \"---->\", desired)\n",
        "\n",
        "for i in range(1, context_size+1):\n",
        "    context = enc_sample[:i]\n",
        "    desired = enc_sample[i]\n",
        "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo4YfNSsSinl",
        "outputId": "49714193-91a5-4ce8-a086-8e48dea5f982"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145 <class 'list'>\n",
            "x: [290, 4920, 2241, 287, 257, 4489, 64, 319, 262, 34686]\n",
            "y:      [4920, 2241, 287, 257, 4489, 64, 319, 262, 34686, 41976]\n",
            "[290] ----> 4920\n",
            "[290, 4920] ----> 2241\n",
            "[290, 4920, 2241] ----> 287\n",
            "[290, 4920, 2241, 287] ----> 257\n",
            "[290, 4920, 2241, 287, 257] ----> 4489\n",
            "[290, 4920, 2241, 287, 257, 4489] ----> 64\n",
            "[290, 4920, 2241, 287, 257, 4489, 64] ----> 319\n",
            "[290, 4920, 2241, 287, 257, 4489, 64, 319] ----> 262\n",
            "[290, 4920, 2241, 287, 257, 4489, 64, 319, 262] ----> 34686\n",
            "[290, 4920, 2241, 287, 257, 4489, 64, 319, 262, 34686] ----> 41976\n",
            " and ---->  established\n",
            " and established ---->  himself\n",
            " and established himself ---->  in\n",
            " and established himself in ---->  a\n",
            " and established himself in a ---->  vill\n",
            " and established himself in a vill ----> a\n",
            " and established himself in a villa ---->  on\n",
            " and established himself in a villa on ---->  the\n",
            " and established himself in a villa on the ---->  Riv\n",
            " and established himself in a villa on the Riv ----> iera\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "btuivItP8qqm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install torch==2.4.0"
      ],
      "metadata": {
        "id": "6gf_tuVvg4KG",
        "outputId": "a698fc51-8671-47d2-fe3e-850d8295c421",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.0\n",
            "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Collecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.8.61)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/797.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:46\u001b[0m\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/797.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:46\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__\n",
        "#torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "w6jTzmraiGVS",
        "outputId": "60890e67-c5a9-43e1-8e35-5a72191b5f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor0d = torch.tensor(1)\n",
        "\n",
        "tensor1d = torch.tensor([1.1, 2, 3])\n",
        "\n",
        "tensor2d = torch.tensor([[1, 2,3],\n",
        "                         [3, 4,5]])\n",
        "\n",
        "tensor3d = torch.tensor([[[1, 2], [3, 4]],\n",
        "                         [[5, 6], [7, 8]]])\n",
        "\n",
        "\n",
        "print(tensor0d)\n",
        "print(tensor1d)\n",
        "print(tensor2d)\n",
        "print(tensor3d)\n",
        "\n",
        "print(tensor1d.dtype)\n",
        "\n",
        "tensor0d = torch.tensor([1, 2, 3])\n",
        "print(tensor0d.dtype)\n",
        "\n",
        "tensor0df = tensor0d.to(torch.float32)\n",
        "print(tensor0df.dtype)\n",
        "print(tensor0d)\n",
        "print(tensor0df)"
      ],
      "metadata": {
        "id": "feB-C38YkqIM",
        "outputId": "ec6c2992-f953-46e4-eebd-7bf92a515b05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1)\n",
            "tensor([1.1000, 2.0000, 3.0000])\n",
            "tensor([[1, 2, 3],\n",
            "        [3, 4, 5]])\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n",
            "torch.float32\n",
            "torch.int64\n",
            "torch.float32\n",
            "tensor([1, 2, 3])\n",
            "tensor([1., 2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor0d, tensor0d.shape)\n",
        "print(tensor1d, tensor1d.shape)\n",
        "print(tensor2d, tensor2d.shape)\n",
        "print(tensor3d, tensor3d.shape)\n",
        "\n",
        "print(tensor2d.reshape(3, 2))\n",
        "\n",
        "print(tensor2d.view(3, 2))\n",
        "\n",
        "\n",
        "print(tensor2d.T)"
      ],
      "metadata": {
        "id": "20Z21rH1mzzz",
        "outputId": "674b7337-65ea-4d3d-aab8-76488b8f6bd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) torch.Size([3])\n",
            "tensor([1.1000, 2.0000, 3.0000]) torch.Size([3])\n",
            "tensor([[1, 2, 3],\n",
            "        [3, 4, 5]]) torch.Size([2, 3])\n",
            "tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]]) torch.Size([2, 2, 2])\n",
            "tensor([[1, 2],\n",
            "        [3, 3],\n",
            "        [4, 5]])\n",
            "tensor([[1, 2],\n",
            "        [3, 3],\n",
            "        [4, 5]])\n",
            "tensor([[1, 3],\n",
            "        [2, 4],\n",
            "        [3, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor2d)\n",
        "print(\"**\")\n",
        "print(tensor2d.T)\n",
        "print(\"MatMul\")\n",
        "print(tensor2d.matmul(tensor2d.T))\n",
        "print(tensor2d @ tensor2d.T)"
      ],
      "metadata": {
        "id": "cRCoMxfhoLvg",
        "outputId": "800a41a7-fc16-459a-a8ad-1029ac8c3519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [3, 4, 5]])\n",
            "**\n",
            "tensor([[1, 3],\n",
            "        [2, 4],\n",
            "        [3, 5]])\n",
            "MatMul\n",
            "tensor([[14, 26],\n",
            "        [26, 50]])\n",
            "tensor([[14, 26],\n",
            "        [26, 50]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeing models as computational graphs.\n",
        "#  A logistic regression forward pass.\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "y = torch.tensor([1.0])\n",
        "x1 = torch.tensor([1.1])\n",
        "w1 = torch.tensor([2.2])\n",
        "b = torch.tensor([0.0])\n",
        "z = x1 * w1 + b\n",
        "a = torch.sigmoid(z)\n",
        "loss = F.binary_cross_entropy(a, y)"
      ],
      "metadata": {
        "id": "1FI38V8ipahX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the gradients via autograd function of torch\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "\n",
        "y = torch.tensor([1.0])\n",
        "x1 = torch.tensor([1.1])\n",
        "w1 = torch.tensor([2.2], requires_grad=True)\n",
        "b = torch.tensor([0.0], requires_grad=True)\n",
        "\n",
        "z = x1 * w1 + b\n",
        "a = torch.sigmoid(z)\n",
        "\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "\n",
        "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
        "grad_L_b = grad(loss, b, retain_graph=True)\n",
        "\n",
        "print(grad_L_w1)\n",
        "print(grad_L_b)\n",
        "\n",
        "print('******************************')\n",
        "\n",
        "loss.backward()\n",
        "print(w1.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "iKZVPHmf2zHY",
        "outputId": "231be9f2-cc55-48a3-c1d7-aee5aa481b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([-0.0898]),)\n",
            "(tensor([-0.0817]),)\n",
            "******************************\n",
            "tensor([-0.0898])\n",
            "tensor([-0.0817])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a multi-layer perceptron with 2 hidden layers\n",
        "import torch.nn as M\n",
        "\n",
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "\n",
        "            # 1st hidden layer\n",
        "            torch.nn.Linear(num_inputs, 30),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # 2nd hidden layer\n",
        "            torch.nn.Linear(30, 20),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # output layer\n",
        "            torch.nn.Linear(20, num_outputs),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "01nQogMI_imX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the above neural network\n",
        "\n",
        "model = NeuralNetwork(50, 3)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# No. of trainable parameters of this model.\n",
        "\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total number of trainable model parameters:\", num_params)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(\"Total number of model parameters:\", total_params)"
      ],
      "metadata": {
        "id": "kE1ZAEVQDTLO",
        "outputId": "2e1ea2e2-cf35-4d4e-d0b0-28b3cb211417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of trainable model parameters: 2213\n",
            "Total number of model parameters: 2213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's print out the weight tensor\n",
        "\n",
        "print(\"Weight Matrix\")\n",
        "print(model.layers[0].weight, model.layers[0].weight.shape, type(model.layers), type(model.layers[0]), (model.layers[0].weight.dtype))\n",
        "\n",
        "print(\"Bias Vector\")\n",
        "print(model.layers[0].bias, model.layers[0].bias.shape, type(model.layers), type(model.layers[0]), (model.layers[0].bias.dtype))"
      ],
      "metadata": {
        "id": "Bf44s1RSIFDR",
        "outputId": "d3c4aac0-c21a-4e3d-edfb-862caaf8f77e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight Matrix\n",
            "Parameter containing:\n",
            "tensor([[ 0.1404, -0.0391,  0.1219,  ..., -0.1195,  0.0136, -0.1377],\n",
            "        [-0.0734,  0.1110,  0.1215,  ...,  0.1370,  0.0806, -0.1129],\n",
            "        [-0.1231, -0.0246, -0.1290,  ..., -0.1213, -0.0708,  0.1316],\n",
            "        ...,\n",
            "        [ 0.0808,  0.0860,  0.1184,  ...,  0.0141,  0.0147, -0.0864],\n",
            "        [-0.0207, -0.0074,  0.1343,  ...,  0.1321, -0.1388,  0.0354],\n",
            "        [ 0.0154, -0.0794, -0.0605,  ..., -0.1230, -0.1142,  0.1391]],\n",
            "       requires_grad=True) torch.Size([30, 50]) <class 'torch.nn.modules.container.Sequential'> <class 'torch.nn.modules.linear.Linear'> torch.float32\n",
            "Bias Vector\n",
            "Parameter containing:\n",
            "tensor([-0.0030,  0.0367, -0.0860, -0.0418, -0.0937,  0.1371,  0.1177,  0.0706,\n",
            "         0.0342, -0.0824,  0.1251,  0.0767,  0.0276, -0.0164,  0.0909,  0.0118,\n",
            "        -0.0506,  0.1109, -0.0391, -0.1404,  0.1047, -0.1009,  0.0106, -0.0979,\n",
            "         0.0295, -0.0504, -0.1323,  0.0943,  0.1179, -0.0085],\n",
            "       requires_grad=True) torch.Size([30]) <class 'torch.nn.modules.container.Sequential'> <class 'torch.nn.modules.linear.Linear'> torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(50, 3)\n",
        "print(model)\n",
        "print(model.layers[0].weight.shape, model.layers[0].bias.shape)\n",
        "print(model.layers[2].weight.shape, model.layers[2].bias.shape)\n",
        "print(model.layers[4].weight.shape, model.layers[4].bias.shape)"
      ],
      "metadata": {
        "id": "UH397K9gMP-E",
        "outputId": "656c7cfa-3982-42c6-e12d-405fc8a222f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([30, 50]) torch.Size([30])\n",
            "torch.Size([20, 30]) torch.Size([20])\n",
            "torch.Size([3, 20]) torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "X = torch.rand((1, 50))\n",
        "print(X)\n",
        "out = torch.softmax(model(X), dim=1)\n",
        "out1 = model(X)\n",
        "print(out)\n",
        "print(out1)\n",
        "\n",
        "print(model.layers[0].weight.shape, model.layers[0].bias.shape)\n",
        "print(model.layers[2].weight.shape, model.layers[2].bias.shape)\n",
        "print(model.layers[4].weight.shape, model.layers[4].bias.shape)\n"
      ],
      "metadata": {
        "id": "k9a-6AU0Mljd",
        "outputId": "5333f466-f1f0-4a97-8a0a-59db8c164629",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740, 0.8665, 0.1366, 0.1025, 0.1841,\n",
            "         0.7264, 0.3153, 0.6871, 0.0756, 0.1966, 0.3164, 0.4017, 0.1186, 0.8274,\n",
            "         0.3821, 0.6605, 0.8536, 0.5932, 0.6367, 0.9826, 0.2745, 0.6584, 0.2775,\n",
            "         0.8573, 0.8993, 0.0390, 0.9268, 0.7388, 0.7179, 0.7058, 0.9156, 0.4340,\n",
            "         0.0772, 0.3565, 0.1479, 0.5331, 0.4066, 0.2318, 0.4545, 0.9737, 0.4606,\n",
            "         0.5159, 0.4220, 0.5786, 0.9455, 0.8057]])\n",
            "tensor([[0.3113, 0.3934, 0.2952]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[-0.1262,  0.1080, -0.1792]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([30, 50]) torch.Size([30])\n",
            "torch.Size([20, 30]) torch.Size([20])\n",
            "torch.Size([3, 20]) torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out = model(X)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMwYOQMwMqvO",
        "outputId": "c2ffd432-90c1-4b54-dcd5-80e5a0d1022a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1262,  0.1080, -0.1792]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    out = torch.softmax(model(X), dim=1)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7NoXvxqNUUn",
        "outputId": "6ea787bb-f97d-498e-8ff3-61b372fbd1b0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3113, 0.3934, 0.2952]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up efficient data loaders and data sets\n",
        "\n",
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "\n",
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6],\n",
        "])\n",
        "y_test = torch.tensor([0, 1])\n"
      ],
      "metadata": {
        "id": "kaHrloBoPtYv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "        print(type(self.features), type(self.labels))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)\n",
        "\n",
        "\n",
        "print(X_train, X_train.shape)\n",
        "print(y_train, y_train.shape)\n",
        "print(train_ds.features, train_ds.labels, train_ds.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrxPRipSQz9p",
        "outputId": "1298fefb-8c93-48a7-cbc4-9ba15d0d2aee"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([[-1.2000,  3.1000],\n",
            "        [-0.9000,  2.9000],\n",
            "        [-0.5000,  2.6000],\n",
            "        [ 2.3000, -1.1000],\n",
            "        [ 2.7000, -1.5000]]) torch.Size([5, 2])\n",
            "tensor([0, 0, 0, 1, 1]) torch.Size([5])\n",
            "tensor([[-1.2000,  3.1000],\n",
            "        [-0.9000,  2.9000],\n",
            "        [-0.5000,  2.6000],\n",
            "        [ 2.3000, -1.1000],\n",
            "        [ 2.7000, -1.5000]]) tensor([0, 0, 0, 1, 1]) 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "print(train_ds.features, train_ds.labels)\n",
        "print(\"**************************************\")\n",
        "\n",
        "en=enumerate(train_loader)\n",
        "print(en)\n",
        "print(\"**************************************\")\n",
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nk2vbdZUt4l",
        "outputId": "862b1522-aa59-442c-c3a1-c1fd73a3cf5f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.2000,  3.1000],\n",
            "        [-0.9000,  2.9000],\n",
            "        [-0.5000,  2.6000],\n",
            "        [ 2.3000, -1.1000],\n",
            "        [ 2.7000, -1.5000]]) tensor([0, 0, 0, 1, 1])\n",
            "**************************************\n",
            "<enumerate object at 0x7ee5557df4c0>\n",
            "**************************************\n",
            "Batch 1: tensor([[ 2.7000, -1.5000],\n",
            "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
            "Batch 2: tensor([[ 2.3000, -1.1000],\n",
            "        [-1.2000,  3.1000]]) tensor([1, 0])\n",
            "Batch 3: tensor([[-0.5000,  2.6000]]) tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "for idx, (x, y) in enumerate(train_loader):\n",
        "    print(f\"Batch {idx+1}:\", x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApRPy8mpbnnq",
        "outputId": "c9c322db-6e3b-47a0-927e-be475c3d41e7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1: tensor([[-0.5000,  2.6000],\n",
            "        [-0.9000,  2.9000]]) tensor([0, 0])\n",
            "Batch 2: tensor([[-1.2000,  3.1000],\n",
            "        [ 2.3000, -1.1000]]) tensor([0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that we have a dataset and dataloader defined. Let's try to use these to train the sample model that we had instantiated few cells above.\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(), lr=0.5\n",
        ")\n",
        "\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "\n",
        "        logits = model(features)\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ### LOGGING\n",
        "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "              f\" | Train Loss: {loss:.2f}\")\n",
        "\n",
        "    model.eval()\n",
        "    # Insert optional model evaluation code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4BK8BSLKdfl",
        "outputId": "19d580fd-23c6-4260-85a7-1067d8d3327c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/003 | Batch 000/002 | Train Loss: 0.75\n",
            "Epoch: 001/003 | Batch 001/002 | Train Loss: 0.65\n",
            "Epoch: 002/003 | Batch 000/002 | Train Loss: 0.44\n",
            "Epoch: 002/003 | Batch 001/002 | Train Loss: 0.13\n",
            "Epoch: 003/003 | Batch 000/002 | Train Loss: 0.03\n",
            "Epoch: 003/003 | Batch 001/002 | Train Loss: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Total number of trainable model parameters:\", num_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1aGBdEPQdNE",
        "outputId": "32798a1f-9541-4d74-a2e8-e5c431f07014"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable model parameters: 752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# above model is trained with x_train and y_train\n",
        "# now do a test with the entire training set. typically we use a validation dataset and then a test dataset\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_train)\n",
        "print(outputs)\n",
        "\n",
        "\n",
        "# apply softmax to get probabilities\n",
        "\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "probas = torch.softmax(outputs, dim=1)\n",
        "print(probas)\n",
        "\n",
        "# convert to 0s and 1s using argmax\n",
        "\n",
        "predictions = torch.argmax(probas, dim=1)\n",
        "print(predictions)\n",
        "\n",
        "predictions = torch.argmax(outputs, dim=1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ewS4JKrUJLm",
        "outputId": "65694191-a24f-4cda-8ba4-3a3761dcf68c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.8569, -4.1618],\n",
            "        [ 2.5382, -3.7548],\n",
            "        [ 2.0944, -3.1820],\n",
            "        [-1.4814,  1.4816],\n",
            "        [-1.7176,  1.7342]])\n",
            "tensor([[    0.9991,     0.0009],\n",
            "        [    0.9982,     0.0018],\n",
            "        [    0.9949,     0.0051],\n",
            "        [    0.0491,     0.9509],\n",
            "        [    0.0307,     0.9693]])\n",
            "tensor([0, 0, 0, 1, 1])\n",
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "\n",
        "predictions == y_train\n",
        "\n",
        "# no. of correct predictions\n",
        "\n",
        "torch.sum(predictions == y_train)\n",
        "\n",
        "# function to compute the prediction accuracy\n",
        "\n",
        "def compute_accuracy(model, dataloader):\n",
        "\n",
        "    model = model.eval()\n",
        "    correct = 0.0\n",
        "    total_examples = 0\n",
        "\n",
        "    for idx, (features, labels) in enumerate(dataloader):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(features)\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        compare = labels == predictions\n",
        "        correct += torch.sum(compare)\n",
        "        total_examples += len(compare)\n",
        "\n",
        "    return (correct / total_examples).item()"
      ],
      "metadata": {
        "id": "1LfbfTI3Wk46"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the accuracy of prediction from above function for our sample model and dataset\n",
        "\n",
        "#on training set\n",
        "print(\"Training Accuracy : \", compute_accuracy(model, train_loader))\n",
        "\n",
        "#on testing set\n",
        "print(\"Test Accuracy : \", compute_accuracy(model, test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBI3V4DhXZrr",
        "outputId": "314da28b-b0d5-4072-e180-2ef87a20ddd1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy :  1.0\n",
            "Test Accuracy :  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Continuing from cell 14...we need now to convert the token ids that the bpe tokernizer created to embeddings\n",
        "\n",
        "# Instantiate Dataset\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt) # use the tiktoken to tokenize the entire text\n",
        "        print(len(token_ids))\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride): #chunking the token ids into overlapping sequences of max_lenght to create sliding window. And convert the list chunks to a tensor\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "           # print(self.input_ids[i], self.target_ids[i])\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "JXyPdsyEZ5Yy"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# following code uses the above dataset to load the inputs in batches via the dataloader\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size, max_length,\n",
        "                         stride, shuffle, drop_last=True,\n",
        "                         num_workers=0):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\") #use openai tiktoken and use gpt2\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride) #create the dataset. this will have 2 lists of tensors\n",
        "    #print(len(dataset.target_ids))\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "RiMdDbpU2LLB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "\n",
        "print(first_batch)\n",
        "\n",
        "#tokenizer.decode(first_batch[1])\n",
        "\n",
        "second_batch = next(data_iter)\n",
        "print(second_batch)\n",
        "\n",
        "\n",
        "\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=1, max_length=2, stride=2, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "\n",
        "print(first_batch)\n",
        "\n",
        "second_batch = next(data_iter)\n",
        "print(second_batch)\n",
        "\n",
        "\n",
        "\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=1, max_length=8, stride=2, shuffle=False)\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "\n",
        "print(first_batch)\n",
        "\n",
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNWH3u6z8Gi5",
        "outputId": "4247b1a7-608a-4409-946f-2467c4ba652c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n",
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n",
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n",
            "5145\n",
            "[tensor([[ 40, 367]]), tensor([[ 367, 2885]])]\n",
            "[tensor([[2885, 1464]]), tensor([[1464, 1807]])]\n",
            "5145\n",
            "[tensor([[  40,  367, 2885, 1464, 1807, 3619,  402,  271]]), tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899]])]\n",
            "[tensor([[ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138]]), tensor([[ 1464,  1807,  3619,   402,   271, 10899,  2138,   257]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, max_length=4, stride=4,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)\n",
        "\n",
        "# NOTE : Note that we increase the stride to 4 to utilize the data set fully (we don’t skip a single word). This avoids any overlap between the batches since more overlap could lead to increased overfitting."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLV3K0HqUqGD",
        "outputId": "a8ecd03e-9c9d-4061-ec38-21e70b81d6b8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n",
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next converting token ids to token emeddings. Preparation involves tokenizing text, converting text tokens to token IDs, and converting token IDs into embedding vectors. Here, we consider the previously created token IDs to create the token embedding vectors.\n",
        "\n",
        "\n",
        "input_ids = torch.tensor([2, 3, 5, 1])\n",
        "vocab_size = 6 # small corpus\n",
        "output_dim = 3 # small dimension for each embedding / token\n",
        "# Note. BPE has vocab of 50,257. And each embedding vector has dim of 12,288\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "print(input_ids)\n",
        "print(\"*****************************************************************\")\n",
        "print(embedding_layer.weight)\n",
        "print(\"*****************************************************************\")\n",
        "# There is one row for each of the six possible tokens in the vocabulary, and there is one column for each of the three embedding dimensions.\n",
        "\n",
        "\n",
        "#let’s apply it to a token ID to obtain the embedding vector:\n",
        "\n",
        "print(embedding_layer(torch.tensor([3])))\n",
        "print(\"*****************************************************************\")\n",
        "# In other words, the embedding layer is essentially a lookup operation that retrieves rows from the embedding layer’s weight matrix via a token ID.\n",
        "\n",
        "print(embedding_layer(input_ids))\n",
        "print(\"*****************************************************************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7KvV-jWYMx6",
        "outputId": "1fc2f62e-da2f-4ac1-f7cb-682c949bd229"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 3, 5, 1])\n",
            "*****************************************************************\n",
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n",
            "*****************************************************************\n",
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n",
            "*****************************************************************\n",
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n",
            "*****************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Having now created embedding vectors from token IDs, next we’ll add a small modification to these embedding vectors to encode positional information about a token within a text.\n",
        "\n",
        "# let's extend the dimensions to 128 and also use the vocab of the tokenizer bpe\n",
        "\n",
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "\n",
        "\n",
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, max_length=max_length,\n",
        "   stride=max_length, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Token IDs:\\n\", inputs)\n",
        "print(\"\\nInputs shape:\\n\", inputs.shape)\n",
        "\n",
        "print(\"Targets IDs:\\n\", targets)\n",
        "print(\"\\nTargets shape:\\n\", targets.shape)\n",
        "\n",
        "\n",
        "#As we can see, the token ID tensor is 8 × 4 dimensional, meaning that the data batch consists of eight text samples with four tokens each.\n",
        "\n",
        "\n",
        "\n",
        "#Let’s now use the embedding layer to embed these token IDs into 256-dimensional vectors:\n",
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(\"\\n Embeddings shape : \\n\", token_embeddings.shape)\n",
        "\n",
        "# The embedding shape 8x4x256 means each token id is now converted to a 256 dim vector\n",
        "\n",
        "# now we need to add absolute (instead of relative) position embedding. It should be of size 4x256\n",
        "\n",
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
        "print(\"\\n Positional Embeddings shape : \\n\", pos_embeddings.shape)\n",
        "\n",
        "print(pos_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LhdUlUlgEPH",
        "outputId": "a3f7c2db-e6a6-49d0-e05c-a5090fcbc304"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n",
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n",
            "Targets IDs:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n",
            "\n",
            "Targets shape:\n",
            " torch.Size([8, 4])\n",
            "\n",
            " Embeddings shape : \n",
            " torch.Size([8, 4, 256])\n",
            "\n",
            " Positional Embeddings shape : \n",
            " torch.Size([4, 256])\n",
            "tensor([[ 1.7375, -0.5620, -0.6303,  ..., -0.2277,  1.5748,  1.0345],\n",
            "        [ 1.6423, -0.7201,  0.2062,  ...,  0.4118,  0.1498, -0.4628],\n",
            "        [-0.4651, -0.7757,  0.5806,  ...,  1.4335, -0.4963,  0.8579],\n",
            "        [-0.6754, -0.4628,  1.4323,  ...,  0.8139, -0.7088,  0.4827]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#he positional embedding tensor consists of four 256-dimensional vectors. We can now add these directly to the token embeddings, where PyTorch will add the 4 × 256–dimensional pos_embeddings tensor to each 4 × 256–dimensional token embedding tensor in each of the eight batches:\n",
        "\n",
        "input_embeddings = token_embeddings + pos_embeddings\n",
        "print(\"\\n Input Embedding : \\n\", input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQeN2eb-uEA1",
        "outputId": "cb24d1f3-bc9b-45fe-a0ec-77f7aa2a5640"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Input Embedding : \n",
            " torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coding Attention Mechanism\n",
        "\n",
        "# Simplified self-attention without trainable weights\n",
        "\n",
        "import torch\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")\n",
        "\n",
        "# intermediary attention score vector w that takes the query vector x^2 and dot product with other input elements.\n",
        "\n",
        "query = inputs[1]\n",
        "print(inputs, inputs.shape)\n",
        "\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "\n",
        "print(\"\\n Instantiate Attention Score vector :\\n\", attn_scores_2, attn_scores_2.shape)\n",
        "\n",
        "for i, x_i in enumerate(inputs):\n",
        "    attn_scores_2[i] = torch.dot(x_i, query)\n",
        "print(\"\\n Attention scores : \\n\", attn_scores_2)\n",
        "\n",
        "#print(torch.dot(torch.tensor([0.4, 0.1, 0.8]), torch.tensor([0.5, 0.8, 0.6])))\n",
        "\n",
        "#Normalize\n",
        "\n",
        "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
        "print(\"\\nAttention weights: \\n\", attn_weights_2_tmp)\n",
        "print(\"Sum:\", attn_weights_2_tmp.sum())\n",
        "\n",
        "#use softmax\n",
        "\n",
        "def softmax_naive(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
        "\n",
        "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
        "print(\"\\nAttention weights with softmax naive: \\n\", attn_weights_2_naive)\n",
        "print(\"\\nSum: \\n\", attn_weights_2_naive.sum())\n",
        "\n",
        "\n",
        "#pytorch softmax - normalize\n",
        "\n",
        "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
        "print(\"\\nAttention weights with PyTorch Softmax: \\n\", attn_weights_2)\n",
        "print(\"\\nSum: \\n\", attn_weights_2.sum())\n",
        "\n",
        "#create context vector\n",
        "\n",
        "query = inputs[1]\n",
        "print(query.shape)\n",
        "context_vec_2 = torch.zeros(query.shape)\n",
        "for i,x_i in enumerate(inputs):\n",
        "    context_vec_2 += attn_weights_2[i]*x_i\n",
        "print(\"\\n Context vector for x2 is : \\n\" , context_vec_2)\n",
        "\n",
        "#context vectors for all input tokens\n",
        "\n",
        "attn_scores = torch.empty(6, 6)\n",
        "for i, x_i in enumerate(inputs):\n",
        "    for j, x_j in enumerate(inputs):\n",
        "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
        "print(\"\\n Attention score tensor :\\n\", attn_scores, type(attn_scores))\n",
        "\n"
      ],
      "metadata": {
        "id": "r3MxARGLuMwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6c3b3b-f683-4090-9816-c3187495750e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4300, 0.1500, 0.8900],\n",
            "        [0.5500, 0.8700, 0.6600],\n",
            "        [0.5700, 0.8500, 0.6400],\n",
            "        [0.2200, 0.5800, 0.3300],\n",
            "        [0.7700, 0.2500, 0.1000],\n",
            "        [0.0500, 0.8000, 0.5500]]) torch.Size([6, 3])\n",
            "\n",
            " Instantiate Attention Score vector :\n",
            " tensor([    0.0000,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000]) torch.Size([6])\n",
            "\n",
            " Attention scores : \n",
            " tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n",
            "\n",
            "Attention weights: \n",
            " tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
            "Sum: tensor(1.0000)\n",
            "\n",
            "Attention weights with softmax naive: \n",
            " tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "\n",
            "Sum: \n",
            " tensor(1.)\n",
            "\n",
            "Attention weights with PyTorch Softmax: \n",
            " tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "\n",
            "Sum: \n",
            " tensor(1.)\n",
            "torch.Size([3])\n",
            "\n",
            " Context vector for x2 is : \n",
            " tensor([0.4419, 0.6515, 0.5683])\n",
            "\n",
            " Attention score tensor :\n",
            " tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]]) <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Jw55sBd7WrlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from above cell we computed 6x6 attention score tensor for input tensor that has 6 tokens with each having 3 dim embedding.\n",
        "\n",
        "# instead of above 2 fors, we can use @\n",
        "\n",
        "attn_scores = inputs @ inputs.T\n",
        "print(\"\\nAttention score tensor :\")\n",
        "print(attn_scores, attn_scores.shape)\n",
        "\n",
        "#normalize using softmax\n",
        "\n",
        "attn_weights = torch.softmax(attn_scores, dim=1)\n",
        "print(\"\\nAttention weights tensor :\")\n",
        "print(attn_weights)\n",
        "\n",
        "#Use attention weights to compute the context vectors\n",
        "\n",
        "all_context_vecs = attn_weights @ inputs\n",
        "print(\"\\n All Context Vecotr:: \\n\",  all_context_vecs)\n",
        "\n",
        "print(\"Previous 2nd context vector:\", context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUjpKsxdWxXM",
        "outputId": "4625aae1-3079-4891-ca32-dd18d4bbae8e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attention score tensor :\n",
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]]) torch.Size([6, 6])\n",
            "\n",
            "Attention weights tensor :\n",
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n",
            "\n",
            " All Context Vecotr:: \n",
            " tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n",
            "Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing self-attention with trainable weights\n",
        "# This self-attention mechanism is also called scaled dot-product attention.\n",
        "# Note that in GPT-like models, the input and output dimensions are usually the same, but to better follow the computation, we’ll use different input (d_in=3) and output (d_out=2) dimensions here.\n",
        "\n",
        "x_2 = inputs[1]\n",
        "d_in = inputs.shape[1]\n",
        "d_out = 2\n",
        "\n",
        "print(d_in, d_out, x_2)\n",
        "\n",
        "# Initialize weight matrices Wq, Wk, and Wv.\n",
        "# we will set requires_grad as True when we train the model\n",
        "\n",
        "torch.manual_seed(123)\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_key   = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "\n",
        "print(\"W_query Shape : \", W_query.shape)\n",
        "print(\"W_key Shape: \", W_key.shape)\n",
        "print(\"W_value shape: \", W_value.shape)\n",
        "# compute the respective vectors\n",
        "\n",
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "print(\"Query Vector Qv for 2nd token : \", query_2)\n",
        "print(\"Key Vector Qv for 2nd token   : \", key_2)\n",
        "print(\"Value Vector Qv for 2nd token : \", value_2)\n",
        "\n",
        "# We can obtain all keys and values via matrix multiplication:\n",
        "queries = inputs @ W_query\n",
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"queries.shape:\", queries.shape)\n",
        "print(\"keys.shape:\", keys.shape)\n",
        "print(\"values.shape:\", values.shape)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Query Vector for entire Input String : \\n\", queries)\n",
        "print(\"Key Vector for entire Input String   : \\n\", keys)\n",
        "print(\"Value Vector for entire Input String : \\n\", values)\n",
        "\n",
        "# Now onto attention score.\n",
        "# The new aspect here is that we are not directly computing the dot-product between the input elements but using the query and key obtained by transforming the inputs via the respective weight matrices.\n",
        "\n",
        "keys_2 = keys[1]\n",
        "attn_score_22 = query_2.dot(keys_2)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Query vector of Input token 2 : \", query_2)\n",
        "print(\"Key vector of Input token 2   : \", keys_2)\n",
        "print(\"Attention score for Input token 2 : \", attn_score_22)\n",
        "\n",
        "# generalize for all attention scores for Query 2 with other keys.\n",
        "\n",
        "attn_scores_2 = query_2 @ keys.T\n",
        "print(attn_scores_2)\n",
        "\n",
        "# Attention Weight\n",
        "#We compute the attention weights by scaling the attention scores and using the softmax function. However, now we scale the attention scores by dividing them by the square root of the embedding dimension of the keys (taking the square root is mathematically the same as exponentiating by 0.5):\n",
        "\n",
        "print(\"\\n\")\n",
        "d_k = keys.shape[-1]\n",
        "d_q = queries.shape[-1]\n",
        "d_v = values.shape[-1]\n",
        "print(\"dimension of k vector : \", d_k)\n",
        "print(\"dimension of q vector : \", d_q)\n",
        "print(\"dimension of v vector : \", d_v)\n",
        "\n",
        "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
        "print(\"Attention Weights for Query 2 in turn Token 2 :\", attn_weights_2)"
      ],
      "metadata": {
        "id": "YG9Rhgyy_h7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff316570-e461-4a4f-db6f-238fadf65610"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 2 tensor([0.5500, 0.8700, 0.6600])\n",
            "W_query Shape :  torch.Size([3, 2])\n",
            "W_key Shape:  torch.Size([3, 2])\n",
            "W_value shape:  torch.Size([3, 2])\n",
            "Query Vector Qv for 2nd token :  tensor([0.4306, 1.4551])\n",
            "Key Vector Qv for 2nd token   :  tensor([0.4433, 1.1419])\n",
            "Value Vector Qv for 2nd token :  tensor([0.3951, 1.0037])\n",
            "\n",
            "\n",
            "queries.shape: torch.Size([6, 2])\n",
            "keys.shape: torch.Size([6, 2])\n",
            "values.shape: torch.Size([6, 2])\n",
            "\n",
            "\n",
            "Query Vector for entire Input String : \n",
            " tensor([[0.2309, 1.0966],\n",
            "        [0.4306, 1.4551],\n",
            "        [0.4300, 1.4343],\n",
            "        [0.2355, 0.7990],\n",
            "        [0.2983, 0.6565],\n",
            "        [0.2568, 1.0533]])\n",
            "Key Vector for entire Input String   : \n",
            " tensor([[0.3669, 0.7646],\n",
            "        [0.4433, 1.1419],\n",
            "        [0.4361, 1.1156],\n",
            "        [0.2408, 0.6706],\n",
            "        [0.1827, 0.3292],\n",
            "        [0.3275, 0.9642]])\n",
            "Value Vector for entire Input String : \n",
            " tensor([[0.1855, 0.8812],\n",
            "        [0.3951, 1.0037],\n",
            "        [0.3879, 0.9831],\n",
            "        [0.2393, 0.5493],\n",
            "        [0.1492, 0.3346],\n",
            "        [0.3221, 0.7863]])\n",
            "\n",
            "\n",
            "Query vector of Input token 2 :  tensor([0.4306, 1.4551])\n",
            "Key vector of Input token 2   :  tensor([0.4433, 1.1419])\n",
            "Attention score for Input token 2 :  tensor(1.8524)\n",
            "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
            "\n",
            "\n",
            "dimension of k vector :  2\n",
            "dimension of q vector :  2\n",
            "dimension of v vector :  2\n",
            "Attention Weights for Query 2 in turn Token 2 : tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
          ]
        }
      ]
    }
  ]
}